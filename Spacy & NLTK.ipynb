{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85bb92c5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (3.6.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (63.4.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (8.1.11)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.10.12)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.9)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.10.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (2.4.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a34a556",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c13094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "523199a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d2e5cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 12.8/12.8 MB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.7.0,>=3.6.0 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from en-core-web-sm==3.6.0) (3.6.0)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.21.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (21.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.64.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.12)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (5.2.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.28.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.11.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (63.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2022.9.14)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\sachin\\appdata\\roaming\\python\\python39\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.6.0\n",
      "\u001b[38;5;3m[!] As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use\n",
      "the full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c26475",
   "metadata": {},
   "source": [
    "# NLTK "
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e336627",
   "metadata": {},
   "source": [
    " token -- The words of a text document/file separated by spaces and punctuation are called as tokens.\n",
    "\n",
    "tokenisation--The process of extracting tokens from a text file/document is referred as tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0544e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing spaCy and creating nlp object\n",
    "\n",
    "nlp=spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54ec2af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP\n",
      "is\n",
      "a\n",
      "very\n",
      "powerful\n",
      "tool\n"
     ]
    }
   ],
   "source": [
    "# Converting text into a spaCy object\n",
    "raw_text = 'NLP is a very powerful tool'\n",
    "text_doc = nlp(raw_text)\n",
    "\n",
    "for text in text_doc:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fda747dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if you want to know if a particular token has alphabetic characters or not?\n",
    "\n",
    "#It can be known by printing  token.is_alpha\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b331174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my True\n",
      "order True\n",
      "number True\n",
      "is True\n",
      "322435 False\n"
     ]
    }
   ],
   "source": [
    "text='my order number is 322435'\n",
    "text_doc=nlp(text)\n",
    "for token in text_doc:\n",
    "    print(token.text,token.is_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f120bc14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d262258",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3068b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As\n",
      "we\n",
      "already\n",
      "established\n",
      ",\n",
      "when\n",
      "performing\n",
      "frequency\n",
      "analysis\n",
      ",\n",
      "stop\n",
      "words\n",
      "need\n",
      "to\n",
      "be\n",
      "removed\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc=nlp('As we already established, when performing frequency analysis, stop words need to be removed.')\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6adef84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "already"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e37a3766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "we already established, when"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c310d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9653596",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp('tony give two $ to pater')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9142f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tony"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token0=doc[0]\n",
    "token0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3c20c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "601cfc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token0.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e136f692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "two"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2=doc[2]\n",
    "token2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce812153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "524b6ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token3=doc[3]\n",
    "token3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecaf0cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token3.is_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "571f9075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tony ==> index:  0 is.alpha: True is_punct: False like_num: False is_currency: False\n",
      "give ==> index:  1 is.alpha: True is_punct: False like_num: False is_currency: False\n",
      "two ==> index:  2 is.alpha: True is_punct: False like_num: True is_currency: False\n",
      "$ ==> index:  3 is.alpha: False is_punct: False like_num: False is_currency: True\n",
      "to ==> index:  4 is.alpha: True is_punct: False like_num: False is_currency: False\n",
      "pater ==> index:  5 is.alpha: True is_punct: False like_num: False is_currency: False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token,\"==>\",\"index: \",token.i,\n",
    "         \"is.alpha:\",token.is_alpha,\n",
    "         \"is_punct:\",token.is_punct,\n",
    "         \"like_num:\",token.like_num,\n",
    "         \"is_currency:\",token.is_currency,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "62bce5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.blank(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0150a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "भाई\n",
      "मेरे\n",
      "100\n",
      "₹\n",
      "कब\n",
      "दे\n",
      "रहे\n",
      "हो\n"
     ]
    }
   ],
   "source": [
    "text=nlp(\"भाई मेरे 100 ₹ कब दे रहे हो\")\n",
    "for token in text:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b9d5decd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "भाई False False\n",
      "मेरे False False\n",
      "100 False True\n",
      "₹ True False\n",
      "कब False False\n",
      "दे False False\n",
      "रहे False False\n",
      "हो False False\n"
     ]
    }
   ],
   "source": [
    "text=nlp(\"भाई मेरे 100 ₹ कब दे रहे हो\")\n",
    "for token in text:\n",
    "    print(token,token.is_currency,token.like_num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f6d57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x204314a4fa0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x2043131fdc0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x20431202580>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x204314b25c0>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x2043151eac0>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x204312025f0>)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fa6175b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c594dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee887d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate part of speech "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4f3a68",
   "metadata": {},
   "source": [
    "# lemmitization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "649dee0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "captain  |  PROPN  |  captain\n",
      "america  |  PROPN  |  america\n",
      "ate  |  VERB  |  eat\n",
      "100  |  NUM  |  100\n",
      "$  |  NUM  |  $\n",
      "of  |  ADP  |  of\n",
      "samosa  |  NOUN  |  samosa\n",
      ".  |  PUNCT  |  .\n",
      "Then  |  ADV  |  then\n",
      "he  |  PRON  |  he\n",
      "said  |  VERB  |  say\n",
      "i  |  PRON  |  I\n",
      "can  |  AUX  |  can\n",
      "do  |  VERB  |  do\n",
      "this  |  PRON  |  this\n",
      "all  |  DET  |  all\n",
      "day  |  NOUN  |  day\n",
      ".  |  PUNCT  |  .\n"
     ]
    }
   ],
   "source": [
    "doc=nlp('captain america ate 100$ of samosa.Then he said i can do this all day.')\n",
    "for token in doc:\n",
    "    print(token , \" | \",token.pos_,\" | \",token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a1cefd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr.sachin  |  NOUN  |  mr.sachin\n",
      "eats  |  VERB  |  eat\n",
      "apple  |  NOUN  |  apple\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(\"Mr.sachin eats apple\")\n",
    "for token in doc:\n",
    "    print(token , \" | \",token.pos_,\" | \",token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b072d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c5ecb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tesla inc  |  ORG  | \n",
      "$45 billion  |  MONEY  | \n"
     ]
    }
   ],
   "source": [
    "doc=nlp(\"tesla inc is going to acquire twitter for $45 billion \")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,\" | \",ent.label_,\" | \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c2dcb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tesla inc  |  ORG  |  Companies, agencies, institutions, etc.\n",
      "$45 billion  |  MONEY  |  Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(\"tesla inc is going to acquire twitter for $45 billion \")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,\" | \",ent.label_,\" | \",spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad627ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    tesla inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is going to acquire twitter for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $45 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc,style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a710d30",
   "metadata": {},
   "source": [
    "# Stemming -- used fixed rules such as remove able , ing , etc  to derive a base word \n",
    "\n",
    "# lemmmatization --- use knowledge of a language to derive a base word \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95fd9b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f77de3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c5ff7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating  |  eat\n",
      "running  |  run\n",
      "swimming  |  swim\n",
      "eats  |  eat\n",
      "eat  |  eat\n",
      "rafting  |  raft\n",
      "ability  |  abil\n",
      "meeting  |  meet\n",
      "better  |  better\n"
     ]
    }
   ],
   "source": [
    "words=[\"eating\",\"running\",\"swimming\",\"eats\",\"eat\",\"rafting\",\"ability\",\"meeting\",'better']\n",
    "for word in words:\n",
    "    print(word,\" | \",stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04077951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization with spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78f5e803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating | eat\n",
      "running | run\n",
      "swimming | swimming\n",
      "eats | eat\n",
      "eat | eat\n",
      "rafting | raft\n",
      "ability | ability\n",
      "meeting | meeting\n",
      "better | well\n"
     ]
    }
   ],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc=nlp(\"eating running swimming eats eat rafting ability meeting better\")\n",
    "for token in doc:\n",
    "    print(token,\"|\",token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19807f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating | eat 9837207709914848172\n",
      "running | run 12767647472892411841\n",
      "swimming | swimming 12526975369366237900\n",
      "eats | eat 9837207709914848172\n",
      "eat | eat 9837207709914848172\n",
      "rafting | raft 7154368781129989833\n",
      "ability | ability 11565809527369121409\n",
      "meeting | meeting 14798207169164081740\n",
      "better | well 4525988469032889948\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(\"eating running swimming eats eat rafting ability meeting better\")\n",
    "for token in doc:\n",
    "    print(token,\"|\",token.lemma_,token.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9f47a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf551f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df182dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum is:  14\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "s=10\n",
    "sum_=4+s\n",
    "print(\"sum is: \",sum_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e5603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
